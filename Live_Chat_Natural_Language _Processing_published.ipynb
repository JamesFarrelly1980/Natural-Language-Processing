{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Chat Natural Language Processing\n",
    "\n",
    "From the conversations recorded on Live chat, we are going to develop a model which can classify whether or not a conversation should be rated good.\n",
    "\n",
    "This should help reclassify those conversations which were not rated in order to help with overall text analysis (done in a later notebook) which should lead to improved customer support and also help to create automation in terms of preempting customer requests.\n",
    "\n",
    "It will also help in the generation of macro and may lead to a the start of an Answer Bot.\n",
    "\n",
    "Lets get started by loading up the data, our usual imports and perhaps a few others like re for delimiting and create our dataframe\n",
    "\n",
    "The text analysis model we will be following for today can be found here\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
    "\n",
    "Unfortunately because of the size of the table and for data protection I can't load the data set for you to repeat the process like I usually do. Following the comments though should provide enough insight for you to complete the process on your own dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_type</th>\n",
       "      <th>rate</th>\n",
       "      <th>duration</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114</td>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Hello. How may I help you?</td>\n",
       "      <td>Mon, 11/12/18 03:06:31 pm</td>\n",
       "      <td>1542035191</td>\n",
       "      <td>operator</td>\n",
       "      <td>not_rated</td>\n",
       "      <td>317</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1114</td>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Iâ€™m trying to change my password</td>\n",
       "      <td>Mon, 11/12/18 03:06:51 pm</td>\n",
       "      <td>1542035211</td>\n",
       "      <td>visitor</td>\n",
       "      <td>not_rated</td>\n",
       "      <td>317</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1114</td>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Okay Drew</td>\n",
       "      <td>Mon, 11/12/18 03:07:07 pm</td>\n",
       "      <td>1542035227</td>\n",
       "      <td>operator</td>\n",
       "      <td>not_rated</td>\n",
       "      <td>317</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1114</td>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Iâ€™ve gone ho</td>\n",
       "      <td>Mon, 11/12/18 03:07:37 pm</td>\n",
       "      <td>1542035257</td>\n",
       "      <td>visitor</td>\n",
       "      <td>not_rated</td>\n",
       "      <td>317</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1114</td>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>page but nothing on account to say about pass...</td>\n",
       "      <td>Mon, 11/12/18 03:07:58 pm</td>\n",
       "      <td>1542035278</td>\n",
       "      <td>visitor</td>\n",
       "      <td>not_rated</td>\n",
       "      <td>317</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page          id                                               text                       date   timestamp user_type       rate  duration  skill\n",
       "0  1114  PI83U5GYOV                         Hello. How may I help you?  Mon, 11/12/18 03:06:31 pm  1542035191  operator  not_rated       317     11\n",
       "1  1114  PI83U5GYOV                   Iâ€™m trying to change my password  Mon, 11/12/18 03:06:51 pm  1542035211   visitor  not_rated       317     11\n",
       "2  1114  PI83U5GYOV                                          Okay Drew  Mon, 11/12/18 03:07:07 pm  1542035227  operator  not_rated       317     11\n",
       "3  1114  PI83U5GYOV                                       Iâ€™ve gone ho  Mon, 11/12/18 03:07:37 pm  1542035257   visitor  not_rated       317     11\n",
       "4  1114  PI83U5GYOV   page but nothing on account to say about pass...  Mon, 11/12/18 03:07:58 pm  1542035278   visitor  not_rated       317     11"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this will keep all our graphs in the page\n",
    "%matplotlib inline\n",
    "\n",
    "# a few libraries that we will need\n",
    "\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#set up pandas table display\n",
    "pd.set_option (\"display.width\", 500)\n",
    "pd.set_option (\"display.max_columns\", 100)\n",
    "pd.set_option (\"display.notebook_repr_html\", True)\n",
    "import seaborn as sns #gives us a bit more style in our plots\n",
    "\n",
    "#We need this to look at excel files\n",
    "import openpyxl\n",
    "\n",
    "from pandas import DataFrame, read_excel, merge\n",
    "\n",
    "file_name = r\"C:\\Users\\Mrs Farrelly\\Documents\\James\\LiveChat\\Live_chat_conversations_public.xlsx\"\n",
    "\n",
    "#table1 = chats_report_October18\n",
    "#this line is key...it calls the str day an actual date\n",
    "dateparse = lambda x:pd.datetime.strptime(x, '%d/%m/%Y %H:%M')\n",
    "#df_chats = pd.read_csv(file_name, header = 0, parse_dates = [\"chat start date Europe/London\"], date_parser = dateparse)\n",
    "\n",
    "\n",
    "#lets create a dataframe using out chats_report_October18.xlsx\n",
    "df_text = pd.read_excel (file_name, sheet_name = \"Sheet2\" , header = 0, date_parser = dateparse)\n",
    "\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Page',\n",
       " 'id',\n",
       " 'text',\n",
       " 'date',\n",
       " 'timestamp',\n",
       " 'user_type',\n",
       " 'rate',\n",
       " 'duration',\n",
       " 'skill']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe based on just three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Hello. How may I help you?</td>\n",
       "      <td>not_rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Iâ€™m trying to change my password</td>\n",
       "      <td>not_rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Okay Drew</td>\n",
       "      <td>not_rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>Iâ€™ve gone ho</td>\n",
       "      <td>not_rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PI83U5GYOV</td>\n",
       "      <td>page but nothing on account to say about pass...</td>\n",
       "      <td>not_rated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text       rate\n",
       "0  PI83U5GYOV                         Hello. How may I help you?  not_rated\n",
       "1  PI83U5GYOV                   Iâ€™m trying to change my password  not_rated\n",
       "2  PI83U5GYOV                                          Okay Drew  not_rated\n",
       "3  PI83U5GYOV                                       Iâ€™ve gone ho  not_rated\n",
       "4  PI83U5GYOV   page but nothing on account to say about pass...  not_rated"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.groupby('id').agg(lambda x: x.tolist())\n",
    "#s.str.cat(sep=', ')\n",
    "#new = old.filter(['A','B','D'], axis=1)\n",
    "#'I, will, hereby, am, gonna, going, far, to, do, this'\n",
    "df_text2 = df_text.filter([\"id\", \"text\",\"rate\"])\n",
    "df_text2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now we need to get all the text onto one like and replace the words 'not_rated' with a 1,  'rated_good' with a 2 and 'rated_bad' with a 3.  The text below will help with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAVJWP07JZ</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello, would you like to talk about our produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAYI9C8DOY</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello Cliff. How may I help you? What is it li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBILEBQTKW</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello, how may I help you? Lee here Hi Lee :) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBVFJEWUEY</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello ben. How may I help you? I'd like help s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NE456RGIDZ</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello George. How may I help you? Hello George...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id rate                                               text\n",
       "0  NAVJWP07JZ    2  Hello, would you like to talk about our produc...\n",
       "1  NAYI9C8DOY    1  Hello Cliff. How may I help you? What is it li...\n",
       "2  NBILEBQTKW    1  Hello, how may I help you? Lee here Hi Lee :) ...\n",
       "3  NBVFJEWUEY    2  Hello ben. How may I help you? I'd like help s...\n",
       "4  NE456RGIDZ    1  Hello George. How may I help you? Hello George..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.groupby(['name','month'])['text'].apply(lambda x: ','.join(x)).reset_index()\n",
    "#df_text2 = df_text2.groupby([\"id\"])[\"text\"].s.str.cat(sep = \" \")\n",
    "df_text2 = df_text2.groupby([\"id\",\"rate\"])[\"text\"].apply(lambda x: ' '.join(x)).reset_index()\n",
    "df_text2 = df_text2.replace(['not_rated','rated_good','rated_bad'], ['1','2','3'])\n",
    "#df['BrandName'].replace(['ABC', 'AB'], 'A')\n",
    "df_text2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27829, 3)\n"
     ]
    }
   ],
   "source": [
    "print (df_text2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello ben. How may I help you? I'd like help sorting something please ok Hello ben. How may I help you? I'd like help sorting something please ok Hello ben. How may I help you? I'd like help sorting something please ok\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at the first line of our text\n",
    "print(\"\\n\".join(df_text2.text[3].split(\"\\n\")[:3])) #prints first line of the first data file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The first thing we have to do is assign part of the data to a training set and then the other part to da testing set.  We don't need to worry about order or anything like that here to begin wiht since we are sorted by \"id\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25046, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.iloc[int(len(df)*0.33):int(len(df)*0.66)]\n",
    "#df[(df.index>np.percentile(df.index, 33))\n",
    "text_train = df_text2[(df_text2.index < np.percentile(df_text2.index, 90))]\n",
    "text_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn has a high level component which will create feature vectors for us â€˜CountVectorizerâ€™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25046, 39399)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "#we must remember to pick the text column from our training data\n",
    "X_train_counts =count_vect.fit_transform(text_train.text)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25046x39399 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1871393 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the amended original script I am following\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#count_vect = CountVectorizer()\n",
    "#X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "#X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF: Just counting the number of words in each document has 1 issue: it will give more weightage to longer documents than shorter documents. To avoid this, we can use frequency (TF - Term Frequencies) i.e. #count(word) / #Total words, in each document.\n",
    "\n",
    "TF-IDF: Finally, we can even reduce the weightage of more common words like (the, is, an etc.) which occurs in all document. This is called as TF-IDF i.e Term Frequency times inverse document frequency.\n",
    "\n",
    "We can achieve both using below line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25046, 39399)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various algorithms which can be used for text classification. We will start with the most simplest one â€˜Naive Bayes (NB)â€™ (donâ€™t think it is too Naive! ðŸ˜ƒ)\n",
    "\n",
    "You can easily build a NBclassifier in scikit using below 2 lines of code: (note - there are many variants of NB, but discussion about them is out of scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#sometimes the rate column is referred to as the target\n",
    "clf = MultinomialNB().fit(X_train_tfidf, text_train.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will train the NB classifier on the training data we provided.\n",
    "\n",
    "Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()), ])\n",
    "\n",
    "text_clf = text_clf.fit(text_train.text, text_train.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names â€˜vectâ€™ , â€˜tfidfâ€™ and â€˜clfâ€™ are arbitrary but will be used later.\n",
    "\n",
    "# Test\n",
    "\n",
    "Performance of NB Classifier: Now we will test the performance of the NB classifier on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803090190441969"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets start by assigning the test data\n",
    "#We shouldn't really need the shuffle column but it can't hurt\n",
    "#remember column names data = text and target = rate\n",
    "text_test = df_text2[(df_text2.index >= np.percentile(df_text2.index, 90))]\n",
    "predicted = text_clf.predict(text_test.text)\n",
    "np.mean(predicted == text_test.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy we get is ~80.31%, which is not bad for start and for a naive classifier. Also, congrats!!! you have now written successfully a text classification algorithm ðŸ‘\n",
    "\n",
    "This is actually way better than I thought I would get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM):\n",
    "\n",
    "We can try a new approach using SVM and see if we can do any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mrs Farrelly\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.803090190441969"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.linear_model import SGDClassifier\n",
    ">>> text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "...                      ('tfidf', TfidfTransformer()),\n",
    "...                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "...                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "... ])\n",
    ">>> _ = text_clf_svm.fit(text_train.text, text_train.rate)\n",
    ">>> predicted_svm = text_clf_svm.predict(text_test.text)\n",
    ">>> np.mean(predicted_svm == text_test.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow, exactly the same value...that's weird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV\n",
    "\n",
    "Almost all the classifiers will have various parameters which can be tuned to obtain optimal performance. Scikit gives an extremely useful tool â€˜GridSearchCVâ€™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.model_selection import GridSearchCV\n",
    ">>> parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "...               'tfidf__use_idf': (True, False),\n",
    "...               'clf__alpha': (1e-2, 1e-3),\n",
    "... }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are creating a list of parameters for which we would like to do performance tuning. All the parameters name start with the classifier name (remember the arbitrary name we gave). E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal.\n",
    "\n",
    "Next, we create an instance of the grid search by passing the classifier, parameters and n_jobs=-1 which tells to use multiple cores from user machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(text_train.text, text_train.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might take few minutes to run depending on the machine configuration.\n",
    "\n",
    "Lastly, to see the best mean score and the params, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9450610875988181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (gs_clf.best_score_)\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has now increased to ~94.51% for the NB classifier (not so naive anymore! ðŸ˜„) and the corresponding parameters are {â€˜clf__alphaâ€™: 0.01, â€˜tfidf__use_idfâ€™: True, â€˜vect__ngram_rangeâ€™: (1, 2)}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats pretty much it for now.  You can now use this fairly accurately to make predictions against new Live chat's or go back over a different data set and reclassify existing chats to be used in either response automation or personel management.  The next step from here is to get the NLTK and start breaking down the text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
